{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Beyond the basics of similarity search\n",
    "\n",
    "\n",
    "![](images/retrieval.png)\n",
    "\n",
    "<font size=\"-1\">source: http://code.flickr.net</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# About me\n",
    "- Studied Physics at Moscow State University and University of Alberta\n",
    "- Worked in Aerospace industry (UrtheCast) for 4 years: telemetry analysis and image processing\n",
    "- Worked for Splunk building ML capabilities in their product line\n",
    "- Now working in internet advertisement industry (MindGeek), building CV and NLP systems\n",
    "- Organize PyData-Montreal meetup events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Practical applications\n",
    "\n",
    "- Classification\n",
    "- Recommender systems\n",
    "- Image retrieval engine\n",
    "- Contextual advertising\n",
    "- etc\n",
    "\n",
    "|_ | _ |\n",
    ":-------------------------:|:-------------------------:\n",
    "<img src=\"images/recommender_systems.png\" style=\"width: 400px;\"/>|<img src=\"images/knn_classification.webp\" alt=\"\" style=\"width: 400px;\"/>\n",
    "\n",
    "<font size=\"-1\">sources: \n",
    "    www.towardsdatascience.com;\n",
    "    www.datacamp.com\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What does it mean to be \"similar\"?\n",
    "\n",
    "![](images/dog_muffin.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Euclidean distance (aka L2 norm)\n",
    "- Manhattan distance (aka L1 norm, aka Taxicab norm)\n",
    "- Hamming distance (aka overlap metric)\n",
    "- Chebyshev distance\n",
    "- Levenshtein distance\n",
    "- Cosine similarity*\n",
    "- Bregman divergence*\n",
    "- and many, many more\n",
    "\n",
    "There are also domain/dataset specific custom metrics: see **metric learning** or **similarity learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Brute-force method\n",
    "\n",
    "![](https://media.giphy.com/media/k9kKWKaUEDBM4/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Given a query data point:\n",
    "- Iterate through all points in the dataset\n",
    "- Compute distances to each one wrt the query point\n",
    "- Sort all points by distance\n",
    "- Return top K points from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Faster methods\n",
    "\n",
    "- Hierarchical Navigable Small World (HNSW)\n",
    "- FAISS\n",
    "- ANNOY\n",
    "\n",
    "### In essence: \n",
    "- Build a data structure in a clever way so that we can only search though a small subset of all points thus speeding up querying.\n",
    "- Even better if we can reduce dimensionality of the data when doing this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# HNSW\n",
    "\n",
    "- NSW algorithm:\n",
    "   - small-world graph: social networks, networks of brain neurons, website navigation, etc\n",
    "   - most `nodes` are not neighbors\n",
    "   - can reach one node to another random node in a small number of steps\n",
    "\n",
    "![](images/small_world.jpg)\n",
    "<font size=\"-1\">source: \n",
    "    https://publications.hse.ru/mirror/pubs/share/folder/x5p6h7thif/direct/128296059\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Layers (hierarchy)\n",
    "\n",
    "<img src=\"images/hnsw.png\" alt=\"\" style=\"width: 400px;\"/>\n",
    "<font size=\"-1\">source: \n",
    "    https://arxiv.org/ftp/arxiv/papers/1603/1603.09320.pdf\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Reduce likelihood of local minimum\n",
    "- Separate into layers based on link length\n",
    "- Traverse each layer until local minimum, start in the next layer from the last point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# FAISS\n",
    "\n",
    "ADC: asymmetric distance computation\n",
    " - every data point is approximated by the centroid of the cluster it belongs to: $ y \\approx q(y) $\n",
    " - quick search to find a closest cluster center, then more refined search within the found cluster\n",
    "\n",
    "![](images/adc.png)\n",
    "\n",
    "<font size=\"-1\">source: \n",
    "    https://www.computer.org/csdl/trans/tp/2011/01/ttp2011010117.html\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "IVF: inverted file\n",
    "   - reverse mapping: from `{vector: centroid}` to `{centroid: list-of-vectors}`\n",
    "   \n",
    "$vec_i -> q_1, vec_j -> q_2, vec_k -> q_2, vec_m -> q_1$\n",
    "\n",
    "becomes\n",
    "\n",
    "$q_1 -> [vec_i, vec_m], q_2 -> [vec_j, vec_k]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "PQ: product quantizer\n",
    "   - quantize remainder vectors: $r(y) = y - q(y)$\n",
    "\n",
    "![](images/quantization.png)\n",
    "<font size=\"-1\">source: \n",
    "    www.inria.fr\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Combine everything together:\n",
    "\n",
    "![](images/ivf_adc.png)\n",
    "\n",
    "<font size=\"-1\">source: \n",
    "    https://hal.inria.fr/inria-00514462v1/document\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ANNOY\n",
    "\n",
    "- Pick two random points\n",
    "- Split the space orthogonally to the \"line\" that connects them\n",
    "- Rinse and repeat until every `leaf` has a \"small\" number of points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](images/annoy_1.png)\n",
    "<font size=\"-1\">source: \n",
    "    https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](images/annoy_2.png)\n",
    "<font size=\"-1\">source: \n",
    "    https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](images/annoy_3.png)\n",
    "<font size=\"-1\">source: \n",
    "    https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](images/annoy_4.png)\n",
    "<font size=\"-1\">source: \n",
    "    https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Additional tricks:\n",
    "- explore the \"wrong\" side of the split\n",
    "- build a forest of trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](images/annoy_5.png)\n",
    "<font size=\"-1\">source: \n",
    "    https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://erikbern.com/assets/2015/09/animated.gif)\n",
    "<font size=\"-1\">source: \n",
    "    https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](images/annoy_6.png)\n",
    "<font size=\"-1\">source: \n",
    "    https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ANNOY summary:\n",
    "\n",
    "Preprocessing time:\n",
    "- Build up a bunch of binary trees. For each tree, split all points recursively by random hyperplanes.\n",
    "\n",
    "Query time:\n",
    "\n",
    "- Insert the root of each tree into the priority queue\n",
    "- Until we have `k` candidates, search all the trees using the priority queue\n",
    "- Remove duplicate candidates\n",
    "- Compute distances to candidates\n",
    "- Sort candidates by distance\n",
    "- Return the top ones\n",
    "\n",
    "<font size=\"-1\">source: \n",
    "    https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example Dataset: GloVe vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-03-05 18:30:36--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2019-03-05 18:30:36--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  5.57MB/s    in 3m 50s  \n",
      "\n",
      "2019-03-05 18:34:27 (3.57 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n",
      "Archive:  glove.6B.zip\n",
      "  inflating: glove_data/glove.6B.50d.txt  \n",
      "  inflating: glove_data/glove.6B.100d.txt  \n",
      "  inflating: glove_data/glove.6B.200d.txt  \n",
      "  inflating: glove_data/glove.6B.300d.txt  \n"
     ]
    }
   ],
   "source": [
    "! wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "! mkdir -p glove_data\n",
    "! unzip glove.6B.zip -d glove_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 0.418 0.24968 -0.41242 0.1217 0.34527 -0.044457 -0.49688 -0.17862 -0.00066023 -0.6566 0.27843 -0.14767 -0.55677 0.14658 -0.0095095 0.011658 0.10204 -0.12792 -0.8443 -0.12181 -0.016801 -0.33279 -0.1552 -0.23131 -0.19181 -1.8823 -0.76746 0.099051 -0.42125 -0.19526 4.0071 -0.18594 -0.52287 -0.31681 0.00059213 0.0074449 0.17778 -0.15897 0.012041 -0.054223 -0.29871 -0.15749 -0.34758 -0.045637 -0.44251 0.18785 0.0027849 -0.18411 -0.11514 -0.78581\r\n"
     ]
    }
   ],
   "source": [
    "! head -n1 glove_data/glove.6B.50d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 s, sys: 1.03 s, total: 17 s\n",
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "glove_vec_dict = {}\n",
    "idx = 0\n",
    "vectors = []\n",
    "words = []\n",
    "word2idx = {}\n",
    "with open('glove_data/glove.6B.50d.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        splt = line.decode().split()\n",
    "        word, vec = str(splt[0]), np.array(splt[1:]).astype(np.float)\n",
    "        words.append(word)\n",
    "        vectors.append(vec)\n",
    "        word2idx[word] = idx        \n",
    "        idx = idx + 1\n",
    "    words = np.array(words)\n",
    "    vectors = np.array(vectors).astype('float32')\n",
    "    glove_word2vec = {words[idx]:vectors[idx] for idx in range(len(words))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76989 ,  1.181   , -1.1299  , -0.74725 , -0.5969  , -1.0518  ,\n",
       "       -0.46552 ,  0.27009 , -0.99243 , -0.04864 ,  0.28642 , -0.75261 ,\n",
       "       -1.0566  , -0.19205 ,  0.572   , -0.24391 , -0.36054 , -0.70876 ,\n",
       "       -0.91951 , -0.27024 ,  1.5131  ,  1.0313  , -0.55713 ,  0.52952 ,\n",
       "       -0.71494 , -1.0949  , -0.60565 ,  0.31329 , -0.44488 ,  0.55915 ,\n",
       "        2.1429  ,  0.43389 , -0.5529  , -0.24261 , -0.43679 , -0.96014 ,\n",
       "        0.25828 ,  0.79385 ,  0.37132 ,  0.49623 ,  0.84359 , -0.25875 ,\n",
       "        1.5616  , -1.1199  ,  0.091676,  0.076675, -0.45084 , -0.86104 ,\n",
       "        0.97599 , -0.35615 ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_word2vec['paris']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21320996,  0.74222   ,  0.23972002,  0.99407   ,  0.51400006,\n",
       "        -0.65760994, -0.302892  , -0.02410699, -1.55212   ,  0.04149997,\n",
       "         0.30327994, -0.27375007, -0.04763797,  1.14008   ,  0.7124    ,\n",
       "         0.98521996, -1.076494  ,  1.0097799 , -0.84392   ,  0.9916    ,\n",
       "         2.6864662 , -0.03069007, -1.0861499 , -0.36579004,  0.8013    ,\n",
       "        -1.4782999 , -0.04848   , -0.04828   , -0.49153   , -0.94323003,\n",
       "         2.5423    ,  0.30223998,  1.14363   , -0.11400002, -0.48376995,\n",
       "        -0.52109   ,  0.36661   , -0.271622  , -0.19778991,  0.20547998,\n",
       "        -1.8284099 , -1.0849429 ,  0.61479986, -0.62539995,  1.078614  ,\n",
       "        -0.21063498, -0.0346    ,  0.30837   ,  0.577846  , -0.17106003]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = glove_word2vec['paris'] - glove_word2vec['france'] + glove_word2vec['japan']\n",
    "vec = vec[None,:]\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "import nmslib\n",
    "from annoy import AnnoyIndex\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.35 ms, sys: 1.54 ms, total: 10.9 ms\n",
      "Wall time: 8.74 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index_brute = NearestNeighbors(n_neighbors=10,\n",
    "                        algorithm='brute',\n",
    "                        n_jobs=-1).fit(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min, sys: 1.73 s, total: 5min 2s\n",
      "Wall time: 40 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index_hnsw = nmslib.init(method='hnsw', space='l2')\n",
    "index_hnsw.addDataPointBatch(vectors)\n",
    "index_hnsw.createIndex({}, print_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.5 ms, sys: 27 ms, total: 54.5 ms\n",
      "Wall time: 52.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index_faiss = faiss.IndexFlatL2(50)\n",
    "index_faiss.add(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.1 s, sys: 125 ms, total: 16.2 s\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index_annoy = AnnoyIndex(vectors.shape[1], metric='euclidean')\n",
    "for i, v in enumerate(vectors):\n",
    "    index_annoy.add_item(i, v)\n",
    "index_annoy.build(n_trees=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def print_neighbors(vec, n_neighbors, index_name):\n",
    "    if index_name == 'brute':\n",
    "        idx_k_nbrs = index_brute.kneighbors(vec,\n",
    "                                 n_neighbors=n_neighbors,\n",
    "                                 return_distance=False)[0]\n",
    "        for idx in idx_k_nbrs:\n",
    "            print(words[idx])\n",
    "    elif index_name == 'hnsw':\n",
    "        idx_k_nbrs, _  = index_hnsw.knnQuery(vec, n_neighbors)\n",
    "        for idx in idx_k_nbrs:\n",
    "            print(words[idx])\n",
    "    elif index_name == 'faiss':\n",
    "        _, idx_k_nbrs = index_faiss.search(vec, n_neighbors)\n",
    "        for idx in idx_k_nbrs[0]:\n",
    "            print(words[idx])\n",
    "    elif index_name == 'annoy':\n",
    "        idx_k_nbrs = index_annoy.get_nns_by_vector(vec[0], n_neighbors)\n",
    "        for idx in idx_k_nbrs:\n",
    "            print(words[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokyo\n",
      "shanghai\n",
      "japan\n",
      "osaka\n",
      "japanese\n",
      "beijing\n",
      "seoul\n",
      "singapore\n",
      "kong\n",
      "taipei\n",
      "CPU times: user 80.4 ms, sys: 124 ms, total: 204 ms\n",
      "Wall time: 1.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print_neighbors(vec=vec, n_neighbors=10, index_name='brute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokyo\n",
      "shanghai\n",
      "japan\n",
      "osaka\n",
      "japanese\n",
      "beijing\n",
      "seoul\n",
      "singapore\n",
      "kong\n",
      "taipei\n",
      "CPU times: user 1.1 ms, sys: 974 µs, total: 2.08 ms\n",
      "Wall time: 1.11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print_neighbors(vec=vec, n_neighbors=10, index_name='hnsw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokyo\n",
      "shanghai\n",
      "japan\n",
      "osaka\n",
      "japanese\n",
      "beijing\n",
      "seoul\n",
      "singapore\n",
      "kong\n",
      "taipei\n",
      "CPU times: user 273 ms, sys: 5.26 ms, total: 278 ms\n",
      "Wall time: 44.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print_neighbors(vec=vec, n_neighbors=10, index_name='faiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokyo\n",
      "shanghai\n",
      "japan\n",
      "japanese\n",
      "singapore\n",
      "kong\n",
      "taipei\n",
      "hong\n",
      "athens\n",
      "korean\n",
      "CPU times: user 346 µs, sys: 28 µs, total: 374 µs\n",
      "Wall time: 380 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print_neighbors(vec=vec, n_neighbors=10, index_name='annoy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary:\n",
    "\n",
    "- The underlying idea the same: \n",
    "    - only check a subset of all points; every algorithm has its own way of selecting the \"best\" subset\n",
    "    - if possible, reduce dimensionality \n",
    "- There is no one \"best\" algorithm - selection of an algorithm will depend on:\n",
    "    - processing time restrictions\n",
    "    - precision/recall requirements\n",
    "    - dataset distribution/structure\n",
    "    - frequency of querying\n",
    "    - frequency of inserting\n",
    "    - hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Interesting tools:\n",
    "- http://ann-benchmarks.com/index.html - industry standard benchmarking tool for ANN\n",
    "- https://euclidesdb.readthedocs.io/en/latest - cool project for performing similarity search in features extracted by Deep Learning models\n",
    "\n",
    "# Blog posts:\n",
    "\n",
    "- https://erikbern.com/2015/09/24/nearest-neighbor-methods-vector-models-part-1.html\n",
    "- https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html\n",
    "- https://www.benfrederickson.com/approximate-nearest-neighbours-for-recommender-systems/\n",
    "- http://mccormickml.com/2017/10/13/product-quantizer-tutorial-part-1/\n",
    "- http://mccormickml.com/2017/10/22/product-quantizer-tutorial-part-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
