{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Beyond the basics of similarity search\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"https://flickrcode.files.wordpress.com/2017/03/retrieval.png\">\n",
    "</center>\n",
    "\n",
    "\n",
    "<font size=\"-1\">source: http://code.flickr.net</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Contents\n",
    "\n",
    "- Practical applications\n",
    "- Similarity and metrics\n",
    "- Brute-force method\n",
    "- Faster (approximate) methods:\n",
    "   - HNSW\n",
    "   - FAISS\n",
    "   - ANNOY\n",
    "- Demo and code\n",
    "- Summary\n",
    "- Where to go next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# About me\n",
    "### Physics -> Data Analysis -> Software Engineering -> Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Practical applications\n",
    "\n",
    "- Classification\n",
    "- Recommender systems\n",
    "- Image retrieval engine\n",
    "- Contextual advertising\n",
    "- etc\n",
    "\n",
    "|_ | _ |\n",
    ":-------------------------:|:-------------------------:\n",
    "<center>\n",
    "<img src=\"images/recommender_systems.png\" style=\"width: 400px;\"/>|<img src=\"images/knn_classification.webp\" alt=\"\" style=\"width: 400px;\"/>\n",
    "</center>\n",
    "\n",
    "<font size=\"-1\">sources: \n",
    "    www.towardsdatascience.com;\n",
    "    www.datacamp.com\n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What does it mean to be \"similar\"?\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"https://www.rover.com/blog/wp-content/uploads/2016/12/chihuahua-or-muffin-food-that-looks-like-dogs.jpg\">\n",
    "</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Euclidean distance (aka L2 norm)\n",
    "- Manhattan distance (aka L1 norm, aka Taxicab norm)\n",
    "- Hamming distance (aka overlap metric)\n",
    "- Chebyshev distance\n",
    "- Levenshtein distance\n",
    "- Cosine similarity*\n",
    "- Bregman divergence*\n",
    "- and many, many more\n",
    "\n",
    "There are also domain/dataset specific custom metrics: see **metric learning** or **similarity learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Brute-force method\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<center>\n",
    "<img src=\"https://media.giphy.com/media/k9kKWKaUEDBM4/giphy.gif\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Given a query data point:\n",
    "- Iterate through all points in the dataset\n",
    "- Compute distances to each one wrt the query point\n",
    "- Sort all points by distance\n",
    "- Return top K points from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Faster methods\n",
    "\n",
    "- Hierarchical Navigable Small World (HNSW)\n",
    "- FAISS\n",
    "- ANNOY\n",
    "\n",
    "### In essence: \n",
    "- Build a data structure in a clever way so that we can only search though a small subset of all points thus speeding up querying.\n",
    "- Even better if we can reduce dimensionality of the data when doing this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# HNSW\n",
    "\n",
    "- NSW algorithm:\n",
    "   - small-world graph: social networks, networks of brain neurons, website navigation, etc\n",
    "   - most `nodes` are not neighbors\n",
    "   - can reach one node to another random node in a small number of steps\n",
    "   \n",
    "<center>\n",
    "<img src=\"https://ars.els-cdn.com/content/image/1-s2.0-S0306437913001300-gr1.jpg\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Layers (hierarchy)\n",
    "\n",
    "<center>\n",
    "<img src=\"https://image.slidesharecdn.com/converted20180822torosn2nickkimfinal-181016013429/95/toros-n2-lightweight-approximate-nearest-neighbor-library-69-638.jpg?cb=1539653734\">\n",
    "</center>\n",
    "\n",
    "\n",
    "<font size=\"-1\">source: \n",
    "    https://arxiv.org/ftp/arxiv/papers/1603/1603.09320.pdf\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- Reduce likelihood of local minimum\n",
    "- Separate into layers based on link length\n",
    "- Traverse each layer until local minimum, start in the next layer from the last point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# FAISS\n",
    "\n",
    "ADC: asymmetric distance computation\n",
    " - every data point is approximated by the centroid of the cluster it belongs to: $ y \\approx q(y) $\n",
    " - quick search to find a closest cluster center, then more refined search within the found cluster\n",
    "\n",
    "<center>\n",
    "<img src=\"images/adc.png\">\n",
    "</center>\n",
    "\n",
    "<font size=\"-1\">source: \n",
    "    https://www.computer.org/csdl/trans/tp/2011/01/ttp2011010117.html\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "IVF: inverted file\n",
    "   - reverse mapping: from `{vector: centroid}` to `{centroid: list-of-vectors}`\n",
    "   \n",
    "$vec_i -> q_1, vec_j -> q_2, vec_k -> q_2, vec_m -> q_1$\n",
    "\n",
    "becomes\n",
    "\n",
    "$q_1 -> [vec_i, vec_m], q_2 -> [vec_j, vec_k]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "PQ: product quantizer\n",
    "   - quantize remainder vectors: $r(y) = y - q(y)$\n",
    "\n",
    "<center>\n",
    "<img src=\"http://mccormickml.com/assets/ProductQuantizer/compression.png\">\n",
    "</center>\n",
    "\n",
    "<font size=\"-1\">source: \n",
    "    www.inria.fr\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Combine everything together:\n",
    "\n",
    "<center>\n",
    "<img src=\"https://www.researchgate.net/profile/Herve_Jegou/publication/47815472/figure/fig3/AS:339497498759180@1457953919644/Overview-of-the-inverted-file-with-asymmetric-distance-computation-IVFADC-indexing.png\">\n",
    "</center>\n",
    "\n",
    "\n",
    "<font size=\"-1\">source: \n",
    "    https://mccormickml.com/2017/10/13/product-quantizer-tutorial-part-1/\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ANNOY\n",
    "\n",
    "- Pick two random points\n",
    "- Split the space orthogonally to the \"line\" that connects them\n",
    "- Rinse and repeat until every `leaf` has a \"small\" number of points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"images/annoy_1.png\">\n",
    "</center>\n",
    "\n",
    "<font size=\"-1\">source: \n",
    "    https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"images/annoy_2.png\">\n",
    "</center>\n",
    "<font size=\"-1\">source: \n",
    "    https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"images/annoy_3.png\">\n",
    "</center>\n",
    "<font size=\"-1\">source: \n",
    "    https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"images/annoy_4.png\">\n",
    "</center>\n",
    "<font size=\"-1\">source: \n",
    "    https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Additional tricks:\n",
    "- explore the \"wrong\" side of the split\n",
    "- build a forest of trees\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"images/annoy_5.png\">\n",
    "</center>\n",
    "<font size=\"-1\">source: \n",
    "    https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://erikbern.com/assets/2015/09/animated.gif)\n",
    "<font size=\"-1\">source: \n",
    "    https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src=\"images/annoy_6.png\">\n",
    "</center>\n",
    "<font size=\"-1\">source: \n",
    "    https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## ANNOY summary:\n",
    "\n",
    "Preprocessing time:\n",
    "- Build up a bunch of binary trees. For each tree, split all points recursively by random hyperplanes.\n",
    "\n",
    "Query time:\n",
    "\n",
    "- Insert the root of each tree into the priority queue\n",
    "- Until we have `k` candidates, search all the trees using the priority queue\n",
    "- Remove duplicate candidates\n",
    "- Compute distances to candidates\n",
    "- Sort candidates by distance\n",
    "- Return the top ones\n",
    "\n",
    "<font size=\"-1\">source: \n",
    "    https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example Dataset: GloVe vectors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# ! wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "# ! mkdir -p glove_data\n",
    "# ! unzip glove.6B.zip -d glove_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 0.418 0.24968 -0.41242 0.1217 0.34527 -0.044457 -0.49688 -0.17862 -0.00066023 -0.6566 0.27843 -0.14767 -0.55677 0.14658 -0.0095095 0.011658 0.10204 -0.12792 -0.8443 -0.12181 -0.016801 -0.33279 -0.1552 -0.23131 -0.19181 -1.8823 -0.76746 0.099051 -0.42125 -0.19526 4.0071 -0.18594 -0.52287 -0.31681 0.00059213 0.0074449 0.17778 -0.15897 0.012041 -0.054223 -0.29871 -0.15749 -0.34758 -0.045637 -0.44251 0.18785 0.0027849 -0.18411 -0.11514 -0.78581\r\n"
     ]
    }
   ],
   "source": [
    "! head -n1 glove_data/glove.6B.50d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.6 s, sys: 1.16 s, total: 11.8 s\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "glove_vec_dict = {}\n",
    "idx = 0\n",
    "vectors = []\n",
    "words = []\n",
    "word2idx = {}\n",
    "with open('glove_data/glove.6B.50d.txt', 'rb') as f:\n",
    "    for line in f:\n",
    "        splt = line.decode().split()\n",
    "        word, vec = str(splt[0]), np.array(splt[1:]).astype(np.float)\n",
    "        words.append(word)\n",
    "        vectors.append(vec)\n",
    "        word2idx[word] = idx        \n",
    "        idx = idx + 1\n",
    "    words = np.array(words)\n",
    "    vectors = np.array(vectors).astype('float32')\n",
    "    glove_word2vec = {words[idx]:vectors[idx] for idx in range(len(words))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76989 ,  1.181   , -1.1299  , -0.74725 , -0.5969  , -1.0518  ,\n",
       "       -0.46552 ,  0.27009 , -0.99243 , -0.04864 ,  0.28642 , -0.75261 ,\n",
       "       -1.0566  , -0.19205 ,  0.572   , -0.24391 , -0.36054 , -0.70876 ,\n",
       "       -0.91951 , -0.27024 ,  1.5131  ,  1.0313  , -0.55713 ,  0.52952 ,\n",
       "       -0.71494 , -1.0949  , -0.60565 ,  0.31329 , -0.44488 ,  0.55915 ,\n",
       "        2.1429  ,  0.43389 , -0.5529  , -0.24261 , -0.43679 , -0.96014 ,\n",
       "        0.25828 ,  0.79385 ,  0.37132 ,  0.49623 ,  0.84359 , -0.25875 ,\n",
       "        1.5616  , -1.1199  ,  0.091676,  0.076675, -0.45084 , -0.86104 ,\n",
       "        0.97599 , -0.35615 ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_word2vec['paris']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.21320996,  0.74222   ,  0.23972002,  0.99407   ,  0.51400006,\n",
       "        -0.65760994, -0.302892  , -0.02410699, -1.55212   ,  0.04149997,\n",
       "         0.30327994, -0.27375007, -0.04763797,  1.14008   ,  0.7124    ,\n",
       "         0.98521996, -1.076494  ,  1.0097799 , -0.84392   ,  0.9916    ,\n",
       "         2.6864662 , -0.03069007, -1.0861499 , -0.36579004,  0.8013    ,\n",
       "        -1.4782999 , -0.04848   , -0.04828   , -0.49153   , -0.94323003,\n",
       "         2.5423    ,  0.30223998,  1.14363   , -0.11400002, -0.48376995,\n",
       "        -0.52109   ,  0.36661   , -0.271622  , -0.19778991,  0.20547998,\n",
       "        -1.8284099 , -1.0849429 ,  0.61479986, -0.62539995,  1.078614  ,\n",
       "        -0.21063498, -0.0346    ,  0.30837   ,  0.577846  , -0.17106003]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = glove_word2vec['paris'] - glove_word2vec['france'] + glove_word2vec['japan']\n",
    "vec = vec[None,:]\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "import nmslib\n",
    "from annoy import AnnoyIndex\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 ms, sys: 0 ns, total: 15.6 ms\n",
      "Wall time: 12.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index_brute = NearestNeighbors(n_neighbors=10,\n",
    "                        algorithm='brute',\n",
    "                        n_jobs=-1).fit(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 48s, sys: 2.53 s, total: 6min 51s\n",
      "Wall time: 38.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index_hnsw = nmslib.init(method='hnsw', space='l2')\n",
    "index_hnsw.addDataPointBatch(vectors)\n",
    "index_hnsw.createIndex({}, print_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.4 s, sys: 469 ms, total: 24.9 s\n",
      "Wall time: 2.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "d = vec.shape[1]\n",
    "nlist = 100\n",
    "m = 5\n",
    "k = 4\n",
    "quantizer = faiss.IndexFlatL2(d)\n",
    "index_faiss = faiss.IndexIVFPQ(quantizer, d, nlist, m, 8)\n",
    "index_faiss.train(vectors)\n",
    "index_faiss.add(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 406 ms, total: 11.5 s\n",
      "Wall time: 9.46 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "index_annoy = AnnoyIndex(vectors.shape[1], metric='euclidean')\n",
    "for i, v in enumerate(vectors):\n",
    "    index_annoy.add_item(i, v)\n",
    "index_annoy.build(n_trees=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def print_neighbors(vec, n_neighbors, index_name):\n",
    "    if index_name == 'brute':\n",
    "        idx_k_nbrs = index_brute.kneighbors(vec,\n",
    "                                 n_neighbors=n_neighbors,\n",
    "                                 return_distance=False)[0]\n",
    "        for idx in idx_k_nbrs:\n",
    "            print(words[idx])\n",
    "    elif index_name == 'hnsw':\n",
    "        idx_k_nbrs, _  = index_hnsw.knnQuery(vec, n_neighbors)\n",
    "        for idx in idx_k_nbrs:\n",
    "            print(words[idx])\n",
    "    elif index_name == 'faiss':\n",
    "        _, idx_k_nbrs = index_faiss.search(vec, n_neighbors)\n",
    "        for idx in idx_k_nbrs[0]:\n",
    "            print(words[idx])\n",
    "    elif index_name == 'annoy':\n",
    "        idx_k_nbrs = index_annoy.get_nns_by_vector(vec[0], n_neighbors)\n",
    "        for idx in idx_k_nbrs:\n",
    "            print(words[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokyo\n",
      "shanghai\n",
      "japan\n",
      "osaka\n",
      "japanese\n",
      "beijing\n",
      "seoul\n",
      "singapore\n",
      "kong\n",
      "taipei\n",
      "CPU times: user 312 ms, sys: 625 ms, total: 938 ms\n",
      "Wall time: 111 ms\n"
     ]
    }
   ],
   "source": [
    "%time print_neighbors(vec=vec, n_neighbors=10, index_name='brute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokyo\n",
      "shanghai\n",
      "japan\n",
      "osaka\n",
      "japanese\n",
      "beijing\n",
      "seoul\n",
      "singapore\n",
      "kong\n",
      "taipei\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 1.29 ms\n"
     ]
    }
   ],
   "source": [
    "%time print_neighbors(vec=vec, n_neighbors=10, index_name='hnsw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokyo\n",
      "japan\n",
      "shanghai\n",
      "athens\n",
      "yen\n",
      "osaka\n",
      "morning\n",
      "kong\n",
      "hong\n",
      "helsinki\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 4.28 ms\n"
     ]
    }
   ],
   "source": [
    "%time print_neighbors(vec=vec, n_neighbors=10, index_name='faiss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokyo\n",
      "shanghai\n",
      "japan\n",
      "japanese\n",
      "beijing\n",
      "seoul\n",
      "singapore\n",
      "kong\n",
      "taipei\n",
      "hong\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 1.23 ms\n"
     ]
    }
   ],
   "source": [
    "%time print_neighbors(vec=vec, n_neighbors=10, index_name='annoy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary:\n",
    "\n",
    "- The underlying idea the same: \n",
    "    - only check a subset of all points; every algorithm has its own way of selecting the \"best\" subset\n",
    "    - if possible, reduce dimensionality \n",
    "- There is no one \"best\" algorithm - selection of an algorithm will depend on:\n",
    "    - processing time restrictions\n",
    "    - precision/recall requirements\n",
    "    - dataset distribution/structure\n",
    "    - frequency of querying\n",
    "    - frequency of inserting\n",
    "    - hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Interesting tools:\n",
    "- http://ann-benchmarks.com/index.html - industry standard benchmarking tool for ANN\n",
    "- https://euclidesdb.readthedocs.io/en/latest - cool project for performing similarity search in features extracted by Deep Learning models\n",
    "\n",
    "# Blog posts:\n",
    "\n",
    "- https://erikbern.com/2015/09/24/nearest-neighbor-methods-vector-models-part-1.html\n",
    "- https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html\n",
    "- https://www.benfrederickson.com/approximate-nearest-neighbours-for-recommender-systems/\n",
    "- http://mccormickml.com/2017/10/13/product-quantizer-tutorial-part-1/\n",
    "- http://mccormickml.com/2017/10/22/product-quantizer-tutorial-part-2/"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
